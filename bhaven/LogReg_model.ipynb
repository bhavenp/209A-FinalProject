{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data is from 2013-2014\n",
    "data_train = pd.read_csv(\"../lipika/cleaned_2013_14\", low_memory = False);\n",
    "#test data is from 2015\n",
    "data_test = pd.read_csv(\"../lipika/cleaned_2015\", low_memory = False);\n",
    "data_test = data_test.dropna(); #drop all rows with NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351757, 49)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that train and test sets have same columns\n",
    "data_test.columns == data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281405, 49)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only want 10% of the training data to train logistic regression model on\n",
    "train_data_subset, train_data_rest = train_test_split(data_train, test_size=0.2, random_state=42);\n",
    "train_data_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into x_train and y_train\n",
    "def split_data(df, cols):\n",
    "    x = df.drop(cols, axis = 1)\n",
    "    y = df.paid\n",
    "    return x, y\n",
    "\n",
    "cols_to_drop_training = ['loan_status', 'paid', 'amnt', 'total_pymnt', 'term_adj'];\n",
    "#split the training subset\n",
    "x_train_subset, y_train_subset = split_data(train_data_subset, cols_to_drop_training)\n",
    "x_train_rest, y_train_rest = split_data(train_data_rest, cols_to_drop_training)\n",
    "#split test data\n",
    "x_test, y_test = split_data(data_test, cols_to_drop_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462496, 44)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upsample default loans (class 1)\n",
    "sm = SMOTE(random_state=42, ratio = 1.0)\n",
    "x_train, y_train = sm.fit_sample(x_train_subset, y_train_subset);\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to take advantage of sklearn make_pipeline\n",
    "#pipeline adds second order terms and interaction terms to X_train and then fits a Logisitic Regression model\n",
    "\n",
    "# def logreg_pipeline(x, y):\n",
    "#     model = make_pipeline(\n",
    "#     PolynomialFeatures(degree=2, include_bias=False),\n",
    "#     LogisticRegressionCV(cv = 5, penalty = 'l2', max_iter = 2500) );\n",
    "#     model.fit(x, y)\n",
    "#     return model\n",
    "\n",
    "def logreg_pipeline(x, y):\n",
    "    model = make_pipeline(\n",
    "    LogisticRegressionCV(cv = 5, penalty = 'l2', max_iter = 2500) );\n",
    "    model.fit(x, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train: 9.163751016666671 min\n"
     ]
    }
   ],
   "source": [
    "from time import clock\n",
    "\n",
    "c = clock();\n",
    "logReg_model = logreg_pipeline(x_train, y_train);\n",
    "stop = clock();\n",
    "\n",
    "print(\"Time to train: {0} min\".format( (stop-c)/60) );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the accuracy score of the Logistic Regression model on the rest of the training data\n",
    "acc_score_rest_training = accuracy_score(y_train_rest, logReg_model.predict(x_train_rest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.648638276097339\n"
     ]
    }
   ],
   "source": [
    "print(acc_score_rest_training)\n",
    "#0.6423 accuracy with just main effects and training on 3% of the training data\n",
    "#0.6527 accuracy with just main effects and training on 10% of the training data\n",
    "#0.64940 accuaracy with just main effects and training on 20% of the training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the logistic regression model on 80% of the training data using just main effects and SMOTE (to upsample the default class), I achieve a <65% prediction accuracy, which seems to be the upper limit. When I add any interaction terms or polynomial features, model fails to converge, so I stuck to just the main effects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
