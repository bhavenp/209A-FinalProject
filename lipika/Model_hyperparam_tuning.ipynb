{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "* Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Import libs and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"cleaned_2013_14\", low_memory = False);\n",
    "data_test = pd.read_csv(\"cleaned_2015\", low_memory = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['funded_amnt', 'int_rate', 'total_pymnt', 'annual_inc', 'dti',\n",
       "       'loan_status', 'revol_util', 'term', 'term_adj', 'emp_length_1 year',\n",
       "       'emp_length_10+ years', 'emp_length_2 years', 'emp_length_3 years',\n",
       "       'emp_length_4 years', 'emp_length_5 years', 'emp_length_6 years',\n",
       "       'emp_length_7 years', 'emp_length_8 years', 'emp_length_9 years',\n",
       "       'emp_length_< 1 year', 'home_ownership_ANY', 'home_ownership_MORTGAGE',\n",
       "       'home_ownership_OWN', 'home_ownership_RENT',\n",
       "       'verification_status_Not Verified',\n",
       "       'verification_status_Source Verified', 'verification_status_Verified',\n",
       "       'grade_A', 'grade_B', 'grade_C', 'grade_D', 'grade_E', 'grade_F',\n",
       "       'grade_G', 'purpose_car', 'purpose_credit_card',\n",
       "       'purpose_debt_consolidation', 'purpose_home_improvement',\n",
       "       'purpose_house', 'purpose_major_purchase', 'purpose_medical',\n",
       "       'purpose_moving', 'purpose_other', 'purpose_renewable_energy',\n",
       "       'purpose_small_business', 'purpose_vacation', 'purpose_wedding', 'amnt',\n",
       "       'paid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = data_test.dropna()\n",
    "data_test.columns == data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, cols):\n",
    "    x = df.drop(cols, axis = 1)\n",
    "    y = df.paid\n",
    "    return x, y\n",
    "\n",
    "cols_to_drop_training = ['loan_status', 'paid', 'amnt', 'total_pymnt', 'term_adj']\n",
    "x_train_initial, y_train_initial = split_data(data_train, cols_to_drop_training)\n",
    "x_test, y_test = split_data(data_test, cols_to_drop_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "        sm = SMOTE(random_state=1, ratio = 1.0)\n",
    "        x_train, y_train = sm.fit_sample(x_train_initial, y_train_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((578050, 44), (346843, 44))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downsample the data to 30% of the full dataset stratifying by classes\n",
    "dont_use_x, x_train_sample, dont_use_y , y_train_sample = train_test_split(x_train, \n",
    "                                                            y_train, test_size = 0.3, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((173415, 44), (173415,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sample.shape, y_train_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pipeline instead of make_pipeline to do grid search\n",
    "pipe = Pipeline([('POLY', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "            ('RFC',RandomForestClassifier(max_features = 100))])\n",
    "\n",
    "# Specify parameters \n",
    "param_grid = {'RFC__n_estimators' : [50,100,120,140],\n",
    "              'RFC__max_depth' : [8,10,12]}\n",
    "\n",
    "# Instantiate GS\n",
    "gs = GridSearchCV(pipe,param_grid, verbose=10, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(x_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on training set:\")\n",
    "print()\n",
    "print(gs.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on training set:\")\n",
    "print()\n",
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_train_preds_true = {'proba' : gs.best_estimator_.predict_proba(x_train_sample)[:, 1], 'true_val' : y_train_sample}\n",
    "train_preds_true = {'proba' : gs.best_estimator_.predict_proba(x_train)[:, 1], 'true_val' : y_train}\n",
    "test_preds_true = {'proba' : gs.best_estimator_.predict_proba(x_test)[:, 1], 'true_val' : y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_sample = roc_auc_score(samp_train_preds_true.true_val, samp_train_preds_true.proba)\n",
    "AUC_train = roc_auc_score(train_preds_true.true_val, train_preds_true.proba)\n",
    "AUC_test = roc_auc_score(test_preds_true.true_val, test_preds_true.proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the trained decision tree classifier with Pickle\n",
    "decision_tree_pkl_filename = 'Tuned_RF.pkl'\n",
    "# Open the file to save as pkl file\n",
    "decision_tree_model_pkl = open(decision_tree_pkl_filename, 'wb')\n",
    "pickle.dump(gs.best_estimator_, decision_tree_model_pkl)\n",
    "# Close the pickle instances\n",
    "decision_tree_model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  LGBM Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pipeline instead of make_pipeline to do grid search\n",
    "pipe = Pipeline([('POLY', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "            ('LGBM',LGBMClassifier(n_estimators = 150)])\n",
    "\n",
    "# Specify parameters \n",
    "param_grid = {'RFC__n_estimators' : [50,100,150],\n",
    "              'RFC__max_depth' : [8,10,12]}\n",
    "\n",
    "# Instantiate GS\n",
    "gs = GridSearchCV(pipe,param_grid, verbose=10, cv=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
