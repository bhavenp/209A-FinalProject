{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.models import load_model\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "\n",
    "## you'll have to pip install LGBM\n",
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"../lipika/cleaned_2013_14\", low_memory = False);\n",
    "data_test = pd.read_csv(\"../lipika/cleaned_2015\", low_memory = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.columns == data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, cols):\n",
    "    x = df.drop(cols, axis = 1)\n",
    "    y = df.paid\n",
    "    return x, y\n",
    "\n",
    "cols_to_drop_training = ['loan_status', 'paid', 'amnt', 'total_pymnt', 'term_adj', 'zip_code']\n",
    "x_train_initial, y_train_initial = split_data(data_train, cols_to_drop_training)\n",
    "x_test, y_test = split_data(data_test, cols_to_drop_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=1, ratio = 1.0)\n",
    "x_train, y_train = sm.fit_sample(x_train_initial, y_train_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test = x_test.dropna()\n",
    "# y_test = y_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('Tuned_RF.pkl', 'rb') as file:  \n",
    "#     rf = pickle.load(file)\n",
    "\n",
    "with open('QDA.pkl', 'rb') as file:  \n",
    "    qda = pickle.load(file)\n",
    "\n",
    "with open('Tuned_LGBM.pkl', 'rb') as file:  \n",
    "    lgbm = pickle.load(file)\n",
    "\n",
    "# with open('../anthony/AdaboostGS.pkl', 'rb') as file:  \n",
    "#     adaboost = pickle.load(file, encoding='latin1')\n",
    "\n",
    "# with open('../bhaven/Tuned_logReg_all_training_data.pkl', 'rb') as file:  \n",
    "#     logreg = pickle.load(file, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [rf, qda, lgbm, adaboost, logreg]\n",
    "models = [ qda,lgbm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(data_1, data_2, penal = 0.5):\n",
    "    df = pd.DataFrame(data_1)\n",
    "    \n",
    "    df['int_rate'] = data_2['int_rate']\n",
    "    df['amnt'] = data_2['amnt']\n",
    "    df['total_pymnt'] = data_2['total_pymnt']\n",
    "    df['term_adj'] = data_2['term_adj']\n",
    "    df['ROI'] = (((1 + df['int_rate'])*(1-df['proba']))+(df['proba']*drr*penal))-1\n",
    "\n",
    "    df['Real_ROI'] = df['amnt']*(((df['total_pymnt']/df['amnt'])**(1/df['term_adj']))-1)\n",
    "    df['annualized_amnt'] = df['amnt']*(1/df['term_adj'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8999757837386156\n"
     ]
    }
   ],
   "source": [
    "distress = data_train[data_train.paid == 1]\n",
    "drr = (np.sum(distress.total_pymnt)/np.sum(distress.amnt))**(1/np.mean(distress.term))\n",
    "print(drr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('POLY', PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)), ('QDA', QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariance=False, store_covariances=None, tol=0.0001))])\n",
      "(346843, 44)\n",
      "346843\n",
      "Pipeline(memory=None,\n",
      "     steps=[('POLY', PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)), ('LGBM', LGBMClassifier(bagging_fraction=0.7, boosting_type='gbdt', class_weight=None,\n",
      "        colsample_bytree=1.0, importance_type='split', lambda_l2=0,\n",
      "        learning_rate=0.1, max_depth=15, metric='binar...0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0))])\n",
      "(346843, 44)\n",
      "346843\n"
     ]
    }
   ],
   "source": [
    "train_data = {}\n",
    "test_data= {}\n",
    "df_train = {}\n",
    "df_test = {}\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    tr = {'proba' : model.predict_proba(x_train)[:, 1], \n",
    "                         'pred' : model.predict(x_train), \n",
    "                         'true_val' : y_train}\n",
    "    df_tr = create_df(tr, data_train)\n",
    "    train_data[model] = tr\n",
    "    df_train[model] = df_tr\n",
    "    \n",
    "    print(x_test.shape)\n",
    "    te = {'proba' : model.predict_proba(x_test)[:, 1], \n",
    "                         'pred' : model.predict(x_test), \n",
    "                         'true_val' : y_test}    \n",
    "    print(len(te['proba']))\n",
    "    df_te = create_df(te, data_test)    \n",
    "    test_data[model] = te\n",
    "    df_test[model] = df_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load neural net\n",
    "# nn = load_model('NN_final_model.h5')\n",
    "\n",
    "# tr = {'proba' : model.predict_proba(x_train)[:, 1], \n",
    "#                          'pred' : model.predict(x_train), \n",
    "#                          'true_val' : y_train}\n",
    "\n",
    "# nn_train = {'proba': nn.predict(x_train)[:, 1], 'true_val': y_train}\n",
    "# nn_test = {'proba': nn.predict(x_test)[:, 1], 'true_val': y_test}\n",
    "\n",
    "# nn_train['pred'] = np.where(nn_train['proba'] > 0.5, 1, 0)\n",
    "# nn_test['pred'] = np.where(nn_test['proba'] > 0.5, 1, 0)\n",
    "\n",
    "# df_train['nn'] = create_df(nn_train, data_train)\n",
    "# df_test['nn'] =  create_df(nn_test, data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "checking = df_train.copy()\n",
    "x = checking.keys()[0]\n",
    "y = checking.keys()[1]\n",
    "checking['lgbm'] = checking.pop(x)\n",
    "checking['qda'] = checking.pop(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "(checking['lgbm']).to_csv('lgbm_preds_training')\n",
    "(checking['qda']).to_csv('qda_preds_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "checking2 = df_test.copy()\n",
    "x = checking2.keys()[0]\n",
    "y = checking2.keys()[1]\n",
    "checking2['lgbm'] = checking2.pop(x)\n",
    "checking2['qda'] = checking2.pop(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "(checking2['lgbm']).to_csv('lgbm_preds_test')\n",
    "(checking2['qda']).to_csv('qda_preds_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('qda_preds_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pred</th>\n",
       "      <th>proba</th>\n",
       "      <th>true_val</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>amnt</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>term_adj</th>\n",
       "      <th>ROI</th>\n",
       "      <th>Real_ROI</th>\n",
       "      <th>annualized_amnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>578050.00000</td>\n",
       "      <td>578050.00000</td>\n",
       "      <td>578050.00000</td>\n",
       "      <td>578050.0</td>\n",
       "      <td>351757.000000</td>\n",
       "      <td>351757.000000</td>\n",
       "      <td>351757.000000</td>\n",
       "      <td>351757.000000</td>\n",
       "      <td>351757.000000</td>\n",
       "      <td>351757.000000</td>\n",
       "      <td>351757.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>289024.50000</td>\n",
       "      <td>0.03485</td>\n",
       "      <td>0.03485</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.139673</td>\n",
       "      <td>14535.219669</td>\n",
       "      <td>16020.345414</td>\n",
       "      <td>2.491042</td>\n",
       "      <td>0.138764</td>\n",
       "      <td>784.427145</td>\n",
       "      <td>10044.041402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>166868.80589</td>\n",
       "      <td>0.18340</td>\n",
       "      <td>0.18340</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.045088</td>\n",
       "      <td>8280.270993</td>\n",
       "      <td>10448.675927</td>\n",
       "      <td>1.216424</td>\n",
       "      <td>0.048514</td>\n",
       "      <td>1888.532793</td>\n",
       "      <td>20816.500166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.567391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>-0.550012</td>\n",
       "      <td>-30375.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>144512.25000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8110.870000</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>365.597597</td>\n",
       "      <td>3265.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>289024.50000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>12500.000000</td>\n",
       "      <td>13452.967630</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>812.909710</td>\n",
       "      <td>5333.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>433536.75000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.167800</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>21867.992610</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>1532.302611</td>\n",
       "      <td>9600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>578049.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567391</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>62884.797380</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.260600</td>\n",
       "      <td>17306.592856</td>\n",
       "      <td>875000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0          pred         proba  true_val       int_rate  \\\n",
       "count  578050.00000  578050.00000  578050.00000  578050.0  351757.000000   \n",
       "mean   289024.50000       0.03485       0.03485       0.5       0.139673   \n",
       "std    166868.80589       0.18340       0.18340       0.5       0.045088   \n",
       "min         0.00000       0.00000       0.00000       0.0       0.060000   \n",
       "25%    144512.25000       0.00000       0.00000       0.0       0.109900   \n",
       "50%    289024.50000       0.00000       0.00000       0.5       0.136700   \n",
       "75%    433536.75000       0.00000       0.00000       1.0       0.167800   \n",
       "max    578049.00000       1.00000       1.00000       1.0       0.567391   \n",
       "\n",
       "                amnt    total_pymnt       term_adj            ROI  \\\n",
       "count  351757.000000  351757.000000  351757.000000  351757.000000   \n",
       "mean    14535.219669   16020.345414       2.491042       0.138764   \n",
       "std      8280.270993   10448.675927       1.216424       0.048514   \n",
       "min         0.567391       0.000000       0.040000      -0.550012   \n",
       "25%      8000.000000    8110.870000       1.583333       0.109900   \n",
       "50%     12500.000000   13452.967630       2.833333       0.136700   \n",
       "75%     20000.000000   21867.992610       3.000000       0.165900   \n",
       "max     35000.000000   62884.797380       5.500000       0.260600   \n",
       "\n",
       "            Real_ROI  annualized_amnt  \n",
       "count  351757.000000    351757.000000  \n",
       "mean      784.427145     10044.041402  \n",
       "std      1888.532793     20816.500166  \n",
       "min    -30375.000000         1.000000  \n",
       "25%       365.597597      3265.384615  \n",
       "50%       812.909710      5333.333333  \n",
       "75%      1532.302611      9600.000000  \n",
       "max     17306.592856    875000.000000  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.pickle', 'wb') as handle:\n",
    "    pickle.dump(df_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('df_test_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(df_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('filename.pickle', 'rb') as handle:\n",
    "#     b = pickle.load(handle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_data[model] = {'proba' : model.predict_proba(x_train)[:, 1], 'pred' : model.predict(x_train), 'true_val' : y_train}\n",
    "# # test_data = {'proba' : rf_complex.predict_proba(x_test)[:, 1], 'pred' : rf_complex.predict(x_test),  'true_val' : y_test}\n",
    "\n",
    "# df_train = create_df(train_data, data_train)\n",
    "# df_test =  create_df(test_data, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_train = np.mean(df_train.ROI)\n",
    "# baseline_test = np.mean(df_test.ROI)\n",
    "# print(baseline_train, baseline_test)\n",
    "# alpha_low = 0\n",
    "# alpha_high = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(roc_auc_score(df_train.true_val, df_train.pred))\n",
    "# print(roc_auc_score(df_test.true_val, df_test.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.sum(df_train.true_val)/df_train.shape[0])\n",
    "# print(1 - np.sum(df_test.true_val)/df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loans_to_buy_train = df_train[(df_train.ROI > alpha_low*baseline_train) & (df_train.ROI < alpha_high*baseline_train)]\n",
    "# loans_to_buy_test = df_test[(df_test.ROI > alpha_low*baseline_test) & (df_test.ROI < alpha_high*baseline_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def return_performance(df_sub, df_main):\n",
    "#     perf_subset = np.sum(df_sub.Real_ROI)/np.sum(df_sub.annualized_amnt)\n",
    "#     perf_mainset = np.sum(df_main.Real_ROI)/np.sum(df_main.annualized_amnt)\n",
    "#     return (perf_subset, perf_mainset, perf_subset - perf_mainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set_performance = return_performance(loans_to_buy_train, df_train)\n",
    "# testing_set_performance = return_performance(loans_to_buy_test, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(15,6));\n",
    "# ax = plt.subplot(1,1,1);\n",
    "\n",
    "# ax.hist(df_test.loc[df_test.true_val == 0,'proba'], density = True, bins = 50, label='Paid Off', alpha=0.6);\n",
    "# ax.hist(df_test.loc[df_test.true_val == 1,'proba'], density = True, bins = 50, label='Defaulted', alpha=0.5);\n",
    "# ax.set_title('Initial Predicted ROI for Defaulted & Non-Defaulted Customers with Higher Order Random Forest')\n",
    "# ax.legend(loc='best')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(15,6));\n",
    "# ax = plt.subplot(1,1,1);\n",
    "\n",
    "# ax.hist(df_train.loc[df_train.true_val == 0,'proba'], bins = 50, label='Paid Off', alpha=0.6);\n",
    "# ax.hist(df_train.loc[df_train.true_val == 1,'proba'], bins = 50, label='Defaulted', alpha=0.5);\n",
    "# ax.set_title('Initial Predicted ROI for Defaulted & Non-Defaulted Customers with Higher Order Random Forest')\n",
    "# ax.legend(loc='best')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.kdeplot(df_train.loc[df_train.true_val == 0,'proba'], label = 'Paid Out');\n",
    "# sns.kdeplot(df_train.loc[df_train.true_val == 1,'proba'], label = 'Defaulted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(16,8)})\n",
    "# sns.kdeplot(df_test.loc[df_test.true_val == 0,'proba'], label = 'Paid Out');\n",
    "# sns.kdeplot(df_test.loc[df_test.true_val == 1,'proba'], label = 'Defaulted', linestyle='--');\n",
    "# plt.ylim(0, 3)\n",
    "# plt.xlim(0, 1);\n",
    "# plt.xlabel('Probability of Default', size = 15);\n",
    "# plt.ylabel('Density of Distributions', size = 15);\n",
    "# plt.legend(prop={'size': 13});\n",
    "# plt.savefig('default_probability_distribution.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.kdeplot(df_test['ROI'], label = '2015 Data');\n",
    "# sns.kdeplot(df_train['ROI'], label = '2014 Data', linestyle='--');\n",
    "# plt.ylim(0, 5)\n",
    "# plt.xlim(-0.5, 0.1);\n",
    "# plt.xlabel('Predicted Return on Investment', size = 15);\n",
    "# plt.ylabel('Density of Distributions', size = 15);\n",
    "# plt.legend(prop={'size': 13});\n",
    "# plt.savefig('ROI_distribution.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
