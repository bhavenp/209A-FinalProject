{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "from lightgbm.sklearn import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"cleaned_2013_14\", low_memory = False);\n",
    "data_test = pd.read_csv(\"cleaned_2015\", low_memory = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = data_test.dropna()\n",
    "data_test.columns == data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, cols):\n",
    "    x = df.drop(cols, axis = 1)\n",
    "    y = df.paid\n",
    "    return x, y\n",
    "\n",
    "cols_to_drop_training = ['loan_status', 'paid', 'amnt', 'total_pymnt', 'term_adj', 'zip_code']\n",
    "x_train_initial, y_train_initial = split_data(data_train, cols_to_drop_training)\n",
    "x_test, y_test = split_data(data_test, cols_to_drop_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=1, ratio = 1.0)\n",
    "x_train, y_train = sm.fit_sample(x_train_initial, y_train_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((578050, 44), (346843, 44))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "params['learning_rate'] = [0.05, 0.01, 0.005, 0.001]\n",
    "params['boosting_type'] = ['gbdt', 'dart']\n",
    "params['max_leaves'] = [2500, 5000, 7500, 10000, 12500, 14000, 16300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pipeline instead of make_pipeline\n",
    "pipe = Pipeline([('POLY', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "            ('LGBM',LGBMClassifier(params, objective = 'binary', metric = 'binary_logloss',\n",
    "                                   n_jobs = 5, bagging_fraction = 0.7))])\n",
    "\n",
    "\n",
    "# lgbm = pipe.fit(x_train, y_train)\n",
    "\n",
    "# Instantiate GS\n",
    "gs = GridSearchCV(pipe, params, verbose=10, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f6496c9ac8ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "gs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on training set:\")\n",
    "print()\n",
    "print(gs.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on training set:\")\n",
    "print()\n",
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds_true = {'proba' : gs.best_estimator_.predict_proba(x_train)[:, 1], 'true_val' : y_train}\n",
    "test_preds_true = {'proba' : gs.best_estimator_.predict_proba(x_test)[:, 1], 'true_val' : y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_train = roc_auc_score(train_preds_true['true_val'], train_preds_true['proba'])\n",
    "AUC_test = roc_auc_score(test_preds_true['true_val'], test_preds_true['proba'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AUC Train: ', AUC_train);\n",
    "print('AUC Test: ', AUC_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Predict\n",
    "# train_predictions = lgbm.predict(x_train)\n",
    "# test_predictions = lgbm.predict(x_test)\n",
    "\n",
    "# ## Accuracy Score\n",
    "# train_score = lgbm.score(x_train, y_train)\n",
    "# test_score = lgbm.score(x_test, y_test)\n",
    "\n",
    "# print(\"train accuracy: \", train_score)\n",
    "# print(\"test accuracy: \", test_score)\n",
    "\n",
    "# ## AUC\n",
    "# train_predictions_class = np.where(train_predictions > 0.5, 1, 0)\n",
    "# test_predictions_class = np.where(test_predictions > 0.5, 1, 0)\n",
    "\n",
    "# print('Train ROC AUC: ', roc_auc_score(train_predictions_class, y_train))\n",
    "# print('Test  ROC AUC: ', roc_auc_score(test_predictions_class, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve\n",
    "# y_pred = lgbm.predict(x_test).ravel()\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "# from sklearn.metrics import auc\n",
    "# auc_lgbm = auc(fpr, tpr)\n",
    "\n",
    "# plt.figure(1)\n",
    "# plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.plot(fpr, tpr, label='LGBM (area = {:.3f})'.format(auc_lgbm))\n",
    "# plt.xlabel('False positive rate')\n",
    "# plt.ylabel('True positive rate')\n",
    "# plt.title('ROC curve')\n",
    "# plt.legend(loc='best')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the tuned classifier with Pickle\n",
    "pkl_filename = 'Tuned_LGBM.pkl'\n",
    "\n",
    "# Open the file to save as pkl file\n",
    "model_pkl = open(pkl_filename, 'wb')\n",
    "pickle.dump(gs.best_estimator_, model_pkl)\n",
    "\n",
    "# Close the pickle instances\n",
    "model_pkl.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
