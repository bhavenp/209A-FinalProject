---
title: 
notebook: 2. Modeling Probability of Default.ipynb
nav_include: 5
---


# 2. Modeling Probability of Default

Modeling the probability that a loan defaults is critical to our investment strategy. After our exploration of 2013 and 2014 data, we select predictors that present promising separations between defaulted and repaid loans. We also make sure not to use any predictors capturing information that we would not have at the time of selecting which loans to invest in.

---

### Summary of variables

**Response:**

Newly defined variable, `paid`, which was a binary variable indicating whether a loan had any status other than 'Fully Paid'. 

**Predictors:**

- `funded_amnt`: The total amount committed to that loan at that point in time.
- `home_ownership` : The home ownership status provided by the borrower during registration or obtained from the credit report.    
- `int_rate` : Interest Rate on the loan.
- `purpose` : A category provided by the borrower for the loan request.
- `annual_inc`: The self-reported annual income provided by the borrower during registration.
- `verification_status`: Indicates if income was verified by LC, not verified, or if the income source was verified.
- `dti`: Debt to income ratio - ratio calculated using the borrower's total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower's self-reported monthly income.
- `revol_util`:  Revolving utilization - ratio of total current balance to credit limit for all revolving accounts.
- `grade`: Lending club assigned loan grade.
- `term`: The number of payments on the loan. Values are in months and can be either 36 or 60.

    *We use one hot encoding for the categorical variables (employment length, home ownership, verification status, grade and purpose).*    
    *We normalize all columns with values that are not percentages (funded amount, annual income and debt-to-income ratio).*
    *We drop rows with null values in any of the columns. This roughly reduces our training data by 
    
    
---



```python

```












```python
data_test = data_2015.copy()
# create response var
data_test["paid"] = 1
data_test.loc[data_test.loan_status == 'Fully Paid', 'paid'] = 0
```








```python
train = pd.read_csv("../lipika/cleaned_2013_14", low_memory = False);
test = pd.read_csv("../lipika/cleaned_2015")
```




```python

```




```python
baseline_test = (len(data_test) - sum(data_test.paid))/len(data_test)
baseline_train = (len(data_train_) - sum(data_train_.paid))/len(data_train_)
```




```python
baseline_test, baseline_train
```




### Handling Imbalanced Class

The algorithms we select to predict future loans as defaulting or not defaulting have trouble learning to predict underrepresented classes. As seen in the table below, the defaulted class in the training data is under represented. 

To address this class imbalance problem, we use synthesis of new minority class instances ([SMOTE](https://jair.org/index.php/jair/article/view/10302/24590)). For each minority class, SMOTE calculates the k nearest neighbors. Depending on the amount of oversampling required, one or more of the k-nearest neighbors are selecte to create synthetic examples to augment the training dataset. We oversample the defaulted loan class to achieve a 50-50 split of classes using the `imbalanced-learn` library.







### Machine Learning Models

The task at hand is to predict the probability that a loan will default. We use a suite of models to predict this probability and conducted hyperparameter searches using grid search. The models used are listed below with their tuned hyperparameters:

- Logistic Regression
- QDA
- Random Forest
    - Max depth: 12
    - Number of estimators: 50
- AdaBoost
    - max_depth: None
    - Number of estimators: 50
    - learning_rate: 1.0
- Light GBM
    - Learning_rate: 0.1
    - boosting_type: gradient boosted decision tree
    - max_depth: 15

- Neural Network
    - Layers: 
   
The baseline accuracy, i.e. accuracy achieved when the majority class (repaid loans) is always predicted, is 0.82 on the training set and 0.78 on the test set. While most of our models do not achieve baseline accuracy, we attribute this to discarding variables we identify as potentially containing information about protected classes.

As displayed in the table below, the highest test accuracy is achieved by the neural network, followed by QDA. However, the reason that QDA achieves a high test accuracy is that it predominantly predicts that loans are repaid (only 0.07\% of loans are predicted to default). A dive QDA's training accuracy reveals a similar pattern, where only 3.4\% of the loans are predicted to default, despite 50% of the loans returning true defaults. Given this trend, we don't trust that QDA has learnt the nuances of our training data, so we choose the next contender, logistic regression, to take forward to our ROI analysis.

As this is a highly imbalanced problem, we sought to confirm that our best contendors from an accuracy standpoint do maximize the area under the receiver operating curve (AUC). The highest AUC is achieved by the logistic regression model, followed by the neural network, confirming our selection.































